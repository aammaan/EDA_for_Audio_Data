{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU Profiler Results:\n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg       CPU Mem  Self CPU Mem    # of Calls  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                        model_inference        16.20%     860.000us       100.00%       5.310ms       5.310ms     797.60 Kb    -228.01 Kb             1  \n",
      "                               Optimizer.step#Adam.step        30.55%       1.622ms        42.18%       2.240ms       2.240ms     795.09 Kb    -795.08 Kb             1  \n",
      "enumerate(DataLoader)#_SingleProcessDataLoaderIter._...         7.70%     409.000us        14.48%     769.000us     384.500us     196.00 Kb           0 b             2  \n",
      "                                           aten::linear         0.32%      17.000us        13.56%     720.000us     360.000us      34.50 Kb           0 b             2  \n",
      "                                            aten::addmm        11.81%     627.000us        12.45%     661.000us     330.500us      34.50 Kb      34.50 Kb             2  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 5.310ms\n",
      "\n",
      "\n",
      "CUDA Profiler Results:\n",
      "------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg       CPU Mem  Self CPU Mem      CUDA Mem  Self CUDA Mem    # of Calls  \n",
      "------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "    Memcpy HtoD (Pageable -> Device)         0.00%       0.000us         0.00%       0.000us       0.000us       9.000us       100.00%       9.000us       9.000us           0 b           0 b           0 b           0 b             1  \n",
      "                            [memory]         0.00%       0.000us         0.00%       0.000us       0.000us       0.000us         0.00%       0.000us       0.000us           0 b           0 b     196.00 Kb     196.00 Kb             5  \n",
      "                  cudaGetDeviceCount         1.93%       1.130ms         1.93%       1.130ms       1.130ms       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b             1  \n",
      "          cudaGetDeviceProperties_v2         0.76%     445.000us         0.76%     445.000us     148.333us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b             3  \n",
      "    cudaDeviceGetStreamPriorityRange        97.07%      56.876ms        97.07%      56.876ms      56.876ms       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b             1  \n",
      "------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 58.590ms\n",
      "Self CUDA time total: 9.000us\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2024-04-23 10:48:27 1984225:1984225 ActivityProfilerController.cpp:312] Completed Stage: Warm Up\n",
      "STAGE:2024-04-23 10:48:27 1984225:1984225 ActivityProfilerController.cpp:318] Completed Stage: Collection\n",
      "STAGE:2024-04-23 10:48:27 1984225:1984225 ActivityProfilerController.cpp:322] Completed Stage: Post Processing\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'prof' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 48\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mCUDA Profiler Results:\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     45\u001b[0m \u001b[39mprint\u001b[39m(prof_cuda\u001b[39m.\u001b[39mkey_averages()\u001b[39m.\u001b[39mtable(sort_by\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mcuda_time_total\u001b[39m\u001b[39m\"\u001b[39m, row_limit\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m))\n\u001b[0;32m---> 48\u001b[0m prof\u001b[39m.\u001b[39mexport_chrome_trace(\u001b[39m\"\u001b[39m\u001b[39mtrace.json\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     50\u001b[0m \u001b[39mwith\u001b[39;00m profile(\n\u001b[1;32m     51\u001b[0m     activities\u001b[39m=\u001b[39m[ProfilerActivity\u001b[39m.\u001b[39mCPU, ProfilerActivity\u001b[39m.\u001b[39mCUDA],\n\u001b[1;32m     52\u001b[0m     with_stack\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m     53\u001b[0m ) \u001b[39mas\u001b[39;00m prof:\n\u001b[1;32m     54\u001b[0m     model(inputs)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'prof' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.profiler import profile, record_function, ProfilerActivity\n",
    "\n",
    "\n",
    "class SimpleModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(784, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "input_data = torch.randn(64, 1, 28, 28)\n",
    "dataset = TensorDataset(input_data)\n",
    "dataloader = DataLoader(dataset, batch_size=64)\n",
    "model = SimpleModel()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Run both profilers simultaneously\n",
    "with profile(activities=[ProfilerActivity.CPU], profile_memory=True, record_shapes=True) as prof_cpu:\n",
    "\n",
    "    with record_function(\"model_inference\"):\n",
    "        for data in dataloader:\n",
    "            inputs = data[0]\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, torch.zeros(64, dtype=torch.long))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "# Print profiler results for CPU\n",
    "print(\"CPU Profiler Results:\")\n",
    "print(prof_cpu.key_averages().table(sort_by=\"cpu_time_total\", row_limit=5))\n",
    "\n",
    "# Print profiler results for CUDA\n",
    "print(\"\\nCUDA Profiler Results:\")\n",
    "print(prof_cuda.key_averages().table(sort_by=\"cuda_time_total\", row_limit=5))\n",
    "\n",
    "\n",
    "prof.export_chrome_trace(\"trace.json\")\n",
    "\n",
    "with profile(\n",
    "    activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA],\n",
    "    with_stack=True,\n",
    ") as prof:\n",
    "    model(inputs)\n",
    "\n",
    "# Print aggregated stats\n",
    "print(prof.key_averages(group_by_stack_n=5).table(sort_by=\"self_cuda_time_total\", row_limit=2))\n",
    "prof.export_stacks(\"/tmp/profiler_stacks.txt\", \"self_cuda_time_total\")\n",
    "\n",
    "from torch.profiler import schedule\n",
    "\n",
    "my_schedule = schedule(\n",
    "    skip_first=10,\n",
    "    wait=5,\n",
    "    warmup=1,\n",
    "    active=3,\n",
    "    repeat=2)\n",
    "\n",
    "def trace_handler(p):\n",
    "    output = p.key_averages().table(sort_by=\"self_cuda_time_total\", row_limit=10)\n",
    "    print(output)\n",
    "    p.export_chrome_trace(\"/tmp/trace_\" + str(p.step_num) + \".json\")\n",
    "\n",
    "with profile(\n",
    "    activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA],\n",
    "    schedule=torch.profiler.schedule(\n",
    "        wait=1,\n",
    "        warmup=1,\n",
    "        active=2),\n",
    "    on_trace_ready=trace_handler\n",
    ") as p:\n",
    "    for idx in range(8):\n",
    "        model(inputs)\n",
    "        p.step()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU Profiler Results:\n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  --------------------------------------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg       CPU Mem  Self CPU Mem    # of Calls                                  Input Shapes  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  --------------------------------------------  \n",
      "                                    cpu_model_inference        19.07%       1.524ms       100.00%       7.992ms       7.992ms     993.60 Kb     -32.01 Kb             1                                            []  \n",
      "                               Optimizer.step#Adam.step        19.68%       1.573ms        29.98%       2.396ms       2.396ms     795.09 Kb    -795.59 Kb             1                                            []  \n",
      "                                           aten::linear         0.24%      19.000us        26.25%       2.098ms       2.098ms      32.00 Kb           0 b             1                [[64, 784], [128, 784], [128]]  \n",
      "                                            aten::addmm        25.51%       2.039ms        25.71%       2.055ms       2.055ms      32.00 Kb      32.00 Kb             1        [[128], [64, 784], [784, 128], [], []]  \n",
      "enumerate(DataLoader)#_SingleProcessDataLoaderIter._...         6.76%     540.000us        10.49%     838.000us     419.000us     196.00 Kb           0 b             2                                            []  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  --------------------------------------------  \n",
      "Self CPU time total: 7.992ms\n",
      "\n",
      "\n",
      "CUDA Profiler Results:\n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg       CPU Mem  Self CPU Mem      CUDA Mem  Self CUDA Mem    # of Calls  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                        ampere_sgemm_32x32_sliced1x4_tn         0.00%       0.000us         0.00%       0.000us       0.000us      12.000us        22.64%      12.000us       6.000us           0 b           0 b           0 b           0 b             2  \n",
      "                       Memcpy HtoD (Pageable -> Device)         0.00%       0.000us         0.00%       0.000us       0.000us       9.000us        16.98%       9.000us       4.500us           0 b           0 b           0 b           0 b             2  \n",
      "void at::native::reduce_kernel<256, 2, at::native::R...         0.00%       0.000us         0.00%       0.000us       0.000us       5.000us         9.43%       5.000us       5.000us           0 b           0 b           0 b           0 b             1  \n",
      "                        ampere_sgemm_64x32_sliced1x4_nt         0.00%       0.000us         0.00%       0.000us       0.000us       5.000us         9.43%       5.000us       5.000us           0 b           0 b           0 b           0 b             1  \n",
      "                        ampere_sgemm_32x32_sliced1x4_nt         0.00%       0.000us         0.00%       0.000us       0.000us       4.000us         7.55%       4.000us       4.000us           0 b           0 b           0 b           0 b             1  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 64.431ms\n",
      "Self CUDA time total: 53.000us\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2024-04-23 10:56:27 1984773:1984773 ActivityProfilerController.cpp:312] Completed Stage: Warm Up\n",
      "STAGE:2024-04-23 10:56:27 1984773:1984773 ActivityProfilerController.cpp:318] Completed Stage: Collection\n",
      "STAGE:2024-04-23 10:56:27 1984773:1984773 ActivityProfilerController.cpp:322] Completed Stage: Post Processing\n",
      "STAGE:2024-04-23 10:56:27 1984773:1984773 ActivityProfilerController.cpp:312] Completed Stage: Warm Up\n",
      "STAGE:2024-04-23 10:56:27 1984773:1984773 ActivityProfilerController.cpp:318] Completed Stage: Collection\n",
      "STAGE:2024-04-23 10:56:27 1984773:1984773 ActivityProfilerController.cpp:322] Completed Stage: Post Processing\n",
      "[W collection.cpp:929] Warning: Failed to recover relationship between all profiler and kineto events: 41 vs. 0  reassociated. (function reassociate)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.profiler import profile, record_function, ProfilerActivity\n",
    "\n",
    "# Define the SimpleModel class\n",
    "class SimpleModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(784, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Create input data, dataset, and dataloader\n",
    "input_data = torch.randn(64, 1, 28, 28)\n",
    "dataset = TensorDataset(input_data)\n",
    "dataloader = DataLoader(dataset, batch_size=64)\n",
    "\n",
    "# Create model, criterion, and optimizer\n",
    "model = SimpleModel()\n",
    "# model.cuda()  # Move model to CUDA device\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "\n",
    "model1 = SimpleModel()\n",
    "model1.cuda()  # Move model to CUDA device\n",
    "criterion1 = nn.CrossEntropyLoss()\n",
    "optimizer1 = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Run both profilers simultaneously\n",
    "with profile(activities=[ProfilerActivity.CPU], profile_memory=True, record_shapes=True) as prof_cpu:\n",
    "    with record_function(\"cpu_model_inference\"):\n",
    "        for data in dataloader:\n",
    "            inputs = data[0]  # No need to move input data to CUDA device within CPU context\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, torch.zeros(64, dtype=torch.long))  # No need to move target to CUDA device within CPU context\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "with profile(activities=[ProfilerActivity.CUDA], profile_memory=True, record_shapes=True) as prof_cuda:\n",
    "    with record_function(\"cuda_model_inference\"):\n",
    "        for data in dataloader:\n",
    "            inputs = data[0].cuda()  # Move input data to CUDA device within CUDA context\n",
    "            outputs = model1(inputs)\n",
    "            loss = criterion1(outputs, torch.zeros(64, dtype=torch.long).cuda())  # Move target to CUDA device within CUDA context\n",
    "            loss.backward()\n",
    "            optimizer1.step()\n",
    "            optimizer1.zero_grad()\n",
    "\n",
    "# Print profiler results for CPU\n",
    "print(\"CPU Profiler Results:\")\n",
    "print(prof_cpu.key_averages(group_by_input_shape=True).table(sort_by=\"cpu_time_total\", row_limit=5))\n",
    "\n",
    "# Print profiler results for CUDA\n",
    "print(\"\\nCUDA Profiler Results:\")\n",
    "print(prof_cuda.key_averages(group_by_input_shape=True).table(sort_by=\"cuda_time_total\", row_limit=5))\n",
    "\n",
    "# Export profiler trace\n",
    "prof_cpu.export_chrome_trace(\"cpu_trace.json\")\n",
    "prof_cuda.export_chrome_trace(\"cuda_trace.json\")\n",
    "\n",
    "\n",
    "\n",
    "with profile(\n",
    "    activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA],\n",
    "    on_trace_ready=lambda trace: trace.export_chrome_trace(\"/tmp/trace_{}.json\".format(trace.step_num))\n",
    ") as p:\n",
    "    for idx in range(10):  \n",
    "        inputs = input_data.cuda()  \n",
    "        model1(inputs)\n",
    "\n",
    "print(p.key_averages().table(sort_by=\"self_cuda_time_total\", row_limit=2))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CROSSCAPS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "85ee25f3913e79dfaf73cc9743a698525d72dde364ea63726e0c3f70211b2c45"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
